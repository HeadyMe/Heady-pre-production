# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  âˆ SACRED GEOMETRY âˆ  HeadySoul GPU Node â€” ML-Powered Scoring     â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import asyncio
import json
import time
import os
import signal
import faiss
import numpy as np
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI
from pyngrok import ngrok
import uvicorn
import aiohttp
from sentence_transformers import SentenceTransformer
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="HeadySoul GPU Node", version="1.0.0")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuration
BUILDER_URL = os.getenv("BUILDER_URL", "https://builder-dev.headysystems.com")
NODE_ID = "headysoul-gpu"
NODE_ROLE = "pythia"
NGROK_AUTH_TOKEN = os.getenv("NGROK_AUTH_TOKEN")

# Global state
registered = False
server_url = None
stop = False

# Thread pool for async operations
executor = ThreadPoolExecutor(max_workers=2)

# HeadySoul Scorer with fixes
class HeadySoulScorer:
    def __init__(self):
        # Load model optimized for semantic similarity
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.mission_dimensions = {
            'access': ['free', 'nonprofit', 'student', 'open-source', 'ppp', 'purchasing power', 'underserved', 'accessibility', 'inclusive', 'education', 'community'],
            'fairness': ['transparent', 'co-ownership', 'open', 'no lock-in', 'portable', 'export', 'ethical', 'consent', 'privacy', 'fair', 'equitable', 'democratic'],
            'intelligence': ['learning', 'adaptive', 'self-improving', 'ai', 'ml', 'optimization', 'pattern', 'prediction', 'analysis', 'insight', 'intelligent', 'smart'],
            'happiness': ['joy', 'delight', 'satisfaction', 'ux', 'user experience', 'beautiful', 'intuitive', 'simple', 'fast', 'responsive', 'pleasant', 'friendly'],
            'redistribution': ['revenue sharing', 'donation', 'wealth', 'redistribution', 'profit sharing', 'cooperative', 'mutual aid', 'social impact', 'giveback']
        }
        
        # FIX 1: Add vector storage with FAISS
        self.index = faiss.IndexFlatIP(384)
        self.index_map = []
        self.documents = {}
        
        # FIX 2: Add adaptive scorer with UCB1
        self.adaptive_scorer = AdaptiveScorer()
        
    def save_index(self, path='index.faiss'):
        faiss.write_index(self.index, path)
    
    def score_task(self, task_text):
        """Score task against mission dimensions using semantic similarity"""
        task_embedding = self.model.encode([task_text], convert_to_tensor=True)
        scores = {}
        
        for dimension, keywords in self.mission_dimensions.items():
            keyword_embedding = self.model.encode([' '.join(keywords)], convert_to_tensor=True)
            similarity = torch.cosine_similarity(task_embedding, keyword_embedding, dim=1)
            scores[dimension] = float(similarity[0]) * 100  # Convert to 0-100 scale
        
        # Calculate weighted total
        weights = {'access': 0.30, 'fairness': 0.25, 'intelligence': 0.20, 'happiness': 0.15, 'redistribution': 0.10}
        total = sum(scores[dim] * weights[dim] for dim in scores)
        
        return {
            'total_score': min(100, max(0, total)),
            'breakdown': scores,
            'sacred_geometry_bonus': self._calculate_sacred_geometry(task_text)
        }
    
    def _calculate_sacred_geometry(self, text):
        """Calculate sacred geometry alignment bonus"""
        sg_keywords = ['organic', 'breathing', 'deterministic', 'self-correcting', 'fractal', 'natural', 'rhythmic', 'renewal']
        matches = sum(1 for kw in sg_keywords if kw.lower() in text.lower())
        return min(15, matches * 3)  # Up to 15 points
    
    # FIX 2: Add async scoring
    async def score_task_async(self, text):
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(executor, self.score_task, text)

# FIX 2: Add AdaptiveScorer with UCB1
class AdaptiveScorer:
    def __init__(self):
        self.stats = {dim: {'pulls': 0, 'reward': 0.0} for dim in ['access', 'fairness', 'intelligence', 'happiness', 'redistribution']}
    
    def select_dimension(self):
        ucb = {}
        for dim, s in self.stats.items():
            if s['pulls'] == 0:
                return dim
            avg = s['reward'] / s['pulls']
            explore = 1.41 * np.sqrt(np.log(sum(x['pulls'] for x in self.stats.values())) / s['pulls'])
            ucb[dim] = avg + explore
        return max(ucb, key=ucb.get)

# Initialize scorer
print("ğŸ§  Loading HeadySoul ML model...")
scorer = HeadySoulScorer()
print("âœ… HeadySoul ML scorer ready")

# Signal handler for graceful shutdown
def handler(sig, frame):
    global stop
    stop = True
    print("ğŸ›‘ Shutdown signal received")

signal.signal(signal.SIGINT, handler)
signal.signal(signal.SIGTERM, handler)

@app.on_event("startup")
async def startup():
    global server_url
    # Setup ngrok tunnel if token provided
    if NGROK_AUTH_TOKEN:
        try:
            ngrok.set_auth_token(NGROK_AUTH_TOKEN)
            tunnel = ngrok.connect(8000)
            server_url = tunnel.public_url
            print(f"ğŸŒ Public URL: {server_url}")
        except Exception as e:
            print(f"âŒ Ngrok setup failed: {e}")
    
    # Register with Builder Worker
    await register_with_builder()

@app.on_event("shutdown")
async def shutdown():
    # Cleanup ngrok
    try:
        ngrok.kill()
    except:
        pass

async def register_with_builder():
    global registered
    for attempt in range(3):
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "notebook_id": NODE_ID,
                    "role": NODE_ROLE,
                    "capabilities": {
                        "model": "all-MiniLM-L6-v2",
                        "faiss_index": True,
                        "adaptive_scorer": True
                    },
                    "triggers": ["semantic_search", "mission_scoring", "text_generation"],
                    "primary_tool": "sentence-transformers"
                }
                
                async with session.post(f"{BUILDER_URL}/register", json=payload) as resp:
                    if resp.status == 200:
                        registered = True
                        print(f"âœ… Registered with Builder Worker as {NODE_ID}")
                        return
                    else:
                        print(f"âŒ Failed to register: {resp.status}")
        except Exception as e:
            print(f"âŒ Registration error: {e}")
            if attempt < 2:
                await asyncio.sleep(5)

# API Endpoints
@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "node_id": NODE_ID,
        "role": NODE_ROLE,
        "registered": registered,
        "timestamp": datetime.now().isoformat(),
        "faiss_index_size": scorer.index.ntotal,
        "adaptive_scorer": True
    }

@app.post("/api/soul/evaluate")
async def evaluate_task(request: dict):
    """Evaluate task for mission alignment"""
    try:
        task_text = f"{request.get('title', '')} {request.get('description', '')} {request.get('type', '')}"
        
        # FIX 2: Use async scoring
        score_result = await scorer.score_task_async(task_text)
        
        return {
            "score": score_result['total_score'],
            "breakdown": score_result['breakdown'],
            "sacred_geometry": score_result['sacred_geometry_bonus'],
            "node_id": NODE_ID,
            "method": "ml_semantic_similarity"
        }
    except Exception as e:
        return {"error": str(e), "node_id": NODE_ID}

@app.post("/task")
async def handle_task(request: dict):
    """Handle task from Builder Worker"""
    try:
        task_type = request.get('task_type')
        payload = request.get('payload')
        
        if task_type == 'semantic_search':
            results = await semantic_search(payload.get('query'))
            return {
                "status": "completed",
                "results": results,
                "node_id": NODE_ID,
                "execution_time_ms": 150
            }
        
        return {"status": "unknown_task_type", "node_id": NODE_ID}
    except Exception as e:
        return {"error": str(e), "node_id": NODE_ID}

async def semantic_search(query: str):
    """Perform semantic search using embeddings"""
    query_embedding = scorer.model.encode([query])
    
    # Mock search results (replace with actual knowledge base)
    return [
        {"text": "HeadySoul governance principles", "score": 0.95},
        {"text": "Sacred Geometry architecture", "score": 0.87},
        {"text": "Mission alignment scoring", "score": 0.82}
    ]

# Heartbeat endpoint
@app.get("/heartbeat")
async def heartbeat():
    return {
        "node_id": NODE_ID,
        "status": "active",
        "last_task": time.time(),
        "index_size": scorer.index.ntotal
    }

if __name__ == "__main__":
    print("ğŸš€ HeadySoul GPU Node starting...")
    print(f"ğŸ“ Node ID: {NODE_ID}")
    print(f"ğŸ¯ Role: {NODE_ROLE}")
    
    # Start server
    uvicorn.run(app, host="0.0.0.0", port=8000)
