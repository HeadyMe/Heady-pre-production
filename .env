# Hugging Face (Required for Model Inference)
# Get from: https://huggingface.co/settings/tokens
HF_TOKEN=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

# Jules Secret
JULES_API_KEY=AQ.Ab8RN6JHPuasMaH5DVl6wDn2oR2ryxmvivDnz2gQBiZaacTd8A

# Google Gemini (Required for Reasoning)
# Get from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=AIzaSyBV_XGEU7xlKBznlNxrbzWBwruuKvGBJFk

# Heady Services (Required for MCP Integration)
# Internal Team Key
HEADY_API_KEY=ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIC9EVyInbapptXhWmlGmvv7oNJNhWaNcpT08NxXnJ+PD heady-system

# Optional: GitHub Enterprise Token
GH_TOKEN=ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIC9EVyInbapptXhWmlGmvv7oNJNhWaNcpT08NxXnJ+PD heady-system
GITHUB_TOKEN=ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIC9EVyInbapptXhWmlGmvv7oNJNhWaNcpT08NxXnJ+PD heady-system

# Database URL (optional, for future features)
DATABASE_URL=postgresql://user:password@localhost:5432/heady

#Cloudflare Secret
CLOUDFLARE_SECRET=c_aFviuAh8cU620Dc7mXtGzfJPO7zRWP85mz508y

# GPU Configuration (optional)
REMOTE_GPU_HOST=gpu.example.com
REMOTE_GPU_PORT=8080
GPU_MEMORY_LIMIT=8192
ENABLE_GPUDIRECT=false

# Admin Settings
HEADY_ADMIN_ENABLE_GPU=false
HEADY_ADMIN_ROOT=/app
HEADY_ADMIN_ALLOWED_PATHS=/app

# Rate Limiting
HEADY_RATE_LIMIT_WINDOW_MS=60000
HEADY_RATE_LIMIT_MAX=120

# Concurrency Limits
HF_MAX_CONCURRENCY=4
HEADY_PY_MAX_CONCURRENCY=2

# Python Worker Settings
HEADY_PY_WORKER_TIMEOUT_MS=90000
HEADY_PYTHON_BIN=python

# QA Settings
HEADY_QA_MAX_NEW_TOKENS=256
HEADY_QA_MAX_QUESTION_CHARS=4000
HEADY_QA_MAX_CONTEXT_CHARS=12000

# Default Models
HF_TEXT_MODEL=gpt2
HF_EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
