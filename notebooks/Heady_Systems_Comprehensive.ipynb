{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {"id": "heady-title"},
   "source": [
    "# HEADY SYSTEMS | Comprehensive Project Notebook\n",
    "\n",
    "```\n",
    "         _   _  _____    _    ____   __   __\n",
    "        | | | || ____|  / \\  |  _ \\ \\ \\ / /\n",
    "        | |_| ||  _|   / _ \\ | | | | \\ V / \n",
    "        |  _  || |___ / ___ \\| |_| |  | |  \n",
    "        |_| |_||_____/_/   \\_\\____/   |_|  \n",
    "```\n",
    "\n",
    "**Sacred Geometry :: Organic Systems :: Breathing Interfaces**\n",
    "\n",
    "---\n",
    "\n",
    "| Section | Topic |\n",
    "|---------|-------|\n",
    "| **I** | System Architecture Overview |\n",
    "| **II** | Environment Setup & Dependencies |\n",
    "| **III** | HeadyManager (Node.js MCP Server) |\n",
    "| **IV** | HeadyConductor (Python Orchestration) |\n",
    "| **V** | HeadyBrain (Central Intelligence) |\n",
    "| **VI** | AI Node Intelligence (JULES, OBSERVER, BUILDER, ATLAS, PYTHIA) |\n",
    "| **VII** | HCFullPipeline & Subsystems |\n",
    "| **VIII** | Data Schema & Storage Architecture |\n",
    "| **IX** | Cloud Layers & Deployment |\n",
    "| **X** | API Reference & Live Testing |\n",
    "| **XI** | Sacred Geometry Quiz & Flashcards |\n",
    "\n",
    "> **Runtime:** Python 3.10+ | **Colab Compatible:** Yes | **Version:** 2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-i"},
   "source": [
    "---\n",
    "## I. System Architecture Overview\n",
    "\n",
    "Heady Systems is a **hybrid Node.js/Python architecture** for deterministic AI orchestration with Sacred Geometry principles.\n",
    "\n",
    "### Core Philosophy: Deterministic Behavior\n",
    "- **Reproducible builds** across all worktrees\n",
    "- **Checkpoint-based recovery** and rollback\n",
    "- **Audit trail integrity** for compliance\n",
    "- **Intelligent routing** based on system state\n",
    "\n",
    "### Tech Stack\n",
    "| Layer | Technology |\n",
    "|-------|------------|\n",
    "| Manager | Node.js (Express, MCP Protocol) |\n",
    "| Worker | Python (HeadyConductor, HeadyBrain) |\n",
    "| Frontend | React (CDN) + Sacred Geometry Aesthetics |\n",
    "| Deployment | Render.com Blueprint |\n",
    "| Database | PostgreSQL (via DATABASE_URL) |\n",
    "| AI/ML | HuggingFace Transformers (PYTHIA node) |\n",
    "\n",
    "### Architecture Diagram\n",
    "```\n",
    "+-----------------------------------------------------------+\n",
    "|                   HEADY SYSTEMS v2.0.0                     |\n",
    "+-----------------------------------------------------------+\n",
    "|  React Frontend  <-->  HeadyManager (Express :3300)        |\n",
    "|                           |                                |\n",
    "|                     MCP Server                             |\n",
    "|                           |                                |\n",
    "|  +----------------------------------------+               |\n",
    "|  |     HeadyConductor (Python)             |               |\n",
    "|  | JULES | OBSERVER | BUILDER | ATLAS | PYTHIA |           |\n",
    "|  +----------------------------------------+               |\n",
    "|                                                            |\n",
    "|  +----------------------------------------+               |\n",
    "|  |  HCFullPipeline + Claude Code Agent     |               |\n",
    "|  |  Supervisor | Brain | Checkpoint        |               |\n",
    "|  |  Readiness  | Health | Cost Tracking    |               |\n",
    "|  +----------------------------------------+               |\n",
    "+-----------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-ii"},
   "source": [
    "---\n",
    "## II. Environment Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "setup-env"},
   "outputs": [],
   "source": [
    "import os, sys, json, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Environment: {'Google Colab' if IN_COLAB else 'Local Jupyter'}\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Timestamp: {datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "setup-clone"},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    REPO_URL = 'https://github.com/HeadySystems/Heady.git'\n",
    "    HEADY_ROOT = Path('/content/Heady')\n",
    "    if not HEADY_ROOT.exists():\n",
    "        !git clone {REPO_URL} {HEADY_ROOT}\n",
    "    os.chdir(HEADY_ROOT)\n",
    "else:\n",
    "    HEADY_ROOT = Path(r'C:\\Users\\erich\\Heady')\n",
    "    if HEADY_ROOT.exists():\n",
    "        os.chdir(HEADY_ROOT)\n",
    "    else:\n",
    "        HEADY_ROOT = Path.cwd()\n",
    "\n",
    "print(f'Heady Root: {HEADY_ROOT}')\n",
    "print(f'Working Dir: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "setup-deps"},
   "outputs": [],
   "source": [
    "REQUIRED = ['requests', 'pyyaml', 'psutil', 'tabulate', 'rich']\n",
    "\n",
    "for pkg in REQUIRED:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        print(f'  [OK] {pkg}')\n",
    "    except ImportError:\n",
    "        print(f'  [INSTALLING] {pkg}...')\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
    "        print(f'  [OK] {pkg}')\n",
    "\n",
    "import requests\n",
    "import yaml\n",
    "from tabulate import tabulate\n",
    "print('\\nAll dependencies ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-iii"},
   "source": [
    "---\n",
    "## III. HeadyManager (Node.js MCP Server)\n",
    "\n",
    "Central orchestration node on **port 3300**.\n",
    "\n",
    "### Responsibilities\n",
    "- API Gateway for all system endpoints\n",
    "- MCP Protocol server for IDE integration\n",
    "- Static file serving for React frontend\n",
    "- Python worker coordination via HeadyConductor\n",
    "- Rate Limiting (1000 req/15min), Caching (5min TTL), Security (Helmet + CORS)\n",
    "\n",
    "### Subsystem Initialization (on startup)\n",
    "1. **Supervisor** - Agent routing (Claude Code integration)\n",
    "2. **SystemBrain** - Auto-tuning and governance\n",
    "3. **CheckpointAnalyzer** - State capture and analysis\n",
    "4. **ReadinessEvaluator** - HTTP + DB probe checks\n",
    "5. **HealthCheckRunner** - Cron-based monitoring (every 5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "manager-health"},
   "outputs": [],
   "source": [
    "MANAGER_URL = 'http://localhost:3300'\n",
    "\n",
    "def check_manager_health():\n",
    "    try:\n",
    "        resp = requests.get(f'{MANAGER_URL}/api/health', timeout=5)\n",
    "        data = resp.json()\n",
    "        print('HeadyManager Status: ONLINE')\n",
    "        print(f\"  Service:  {data.get('service')}\")\n",
    "        print(f\"  Version:  {data.get('version')}\")\n",
    "        print(f\"  Uptime:   {data.get('uptime', 0):.1f}s\")\n",
    "        mem = data.get('memory', {})\n",
    "        if mem:\n",
    "            print(f\"  Memory:   RSS={mem.get('rss',0)/1048576:.1f}MB, Heap={mem.get('heapUsed',0)/1048576:.1f}MB\")\n",
    "        return data\n",
    "    except requests.ConnectionError:\n",
    "        print('HeadyManager Status: OFFLINE')\n",
    "        print('  Start with: node heady-manager.js')\n",
    "        return None\n",
    "\n",
    "health = check_manager_health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "manager-registry"},
   "outputs": [],
   "source": [
    "def load_registry():\n",
    "    registry_path = HEADY_ROOT / 'heady-registry.json'\n",
    "    if registry_path.exists():\n",
    "        with open(registry_path) as f:\n",
    "            return json.load(f)\n",
    "    try:\n",
    "        return requests.get(f'{MANAGER_URL}/api/registry', timeout=5).json()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "registry = load_registry()\n",
    "if registry:\n",
    "    print(f\"Registry Version: {registry.get('registryVersion', 'unknown')}\")\n",
    "    comps = registry.get('components', [])\n",
    "    print(f\"Components ({len(comps)}):\\n\")\n",
    "    rows = [[c.get('id',''), c.get('name',''), c.get('type',''), c.get('status',''),\n",
    "             ', '.join(c.get('responsibilities',[])[:3])] for c in comps]\n",
    "    print(tabulate(rows, headers=['ID','Name','Type','Status','Responsibilities'], tablefmt='grid'))\n",
    "else:\n",
    "    print('Registry not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-iv"},
   "source": [
    "---\n",
    "## IV. HeadyConductor (Python Orchestration)\n",
    "\n",
    "Python-side orchestration layer:\n",
    "\n",
    "| Class | File | Purpose |\n",
    "|-------|------|---------|\n",
    "| `HeadyConductor` | `HeadyAcademy/HeadyConductor.py` | Supreme orchestration authority |\n",
    "| `HeadyRegistry` | `HeadyAcademy/HeadyRegistry.py` | Component/workflow/tool index |\n",
    "| `HeadyLens` | `HeadyAcademy/HeadyLens.py` | Real-time monitoring |\n",
    "| `HeadyMemory` | `HeadyAcademy/HeadyMemory.py` | Persistent memory storage |\n",
    "| `HeadyBrain` | `HeadyAcademy/HeadyBrain.py` | Central intelligence coordinator |\n",
    "\n",
    "### Request Analysis Flow\n",
    "```\n",
    "User Request\n",
    "  |-> Match Workflows (slash_command, name, description keywords)\n",
    "  |-> Match Nodes (trigger_on, role, name)\n",
    "  |-> Match Tools (tool_name in request)\n",
    "  |-> Detect Services (keyword categories)\n",
    "  |-> Execution Plan (confidence-scored, conductor-optimized)\n",
    "```\n",
    "\n",
    "### Confidence Scoring\n",
    "- Slash command match: **0.95**\n",
    "- Workflow name match: **0.85**\n",
    "- Trigger match: **0.85**\n",
    "- Role match: **0.80**\n",
    "- Description keyword overlap (>=2): **0.75**\n",
    "- Conductor authority boost: **x1.1** (max 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "conductor-explore"},
   "outputs": [],
   "source": [
    "academy_path = HEADY_ROOT / 'HeadyAcademy'\n",
    "\n",
    "if academy_path.exists():\n",
    "    py_files = sorted(academy_path.glob('*.py'))\n",
    "    print(f'HeadyAcademy Python Modules ({len(py_files)}):\\n')\n",
    "    rows = []\n",
    "    for f in py_files:\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        first_class = ''\n",
    "        with open(f, 'r', encoding='utf-8', errors='ignore') as fh:\n",
    "            for line in fh:\n",
    "                if line.strip().startswith('class '):\n",
    "                    first_class = line.strip()[:60]\n",
    "                    break\n",
    "        rows.append([f.name, f'{size_kb:.1f} KB', first_class])\n",
    "    print(tabulate(rows, headers=['Module', 'Size', 'Entry Class'], tablefmt='grid'))\n",
    "else:\n",
    "    print('HeadyAcademy directory not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "conductor-api"},
   "outputs": [],
   "source": [
    "def conductor_orchestrate(request_text):\n",
    "    try:\n",
    "        resp = requests.post(f'{MANAGER_URL}/api/conductor/orchestrate',\n",
    "                             json={'request': request_text}, timeout=30)\n",
    "        return resp.json()\n",
    "    except requests.ConnectionError:\n",
    "        return {'error': 'HeadyManager offline'}\n",
    "\n",
    "# Example orchestration\n",
    "result = conductor_orchestrate('optimization analysis on the codebase')\n",
    "print(json.dumps(result, indent=2, default=str)[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-v"},
   "source": [
    "---\n",
    "## V. HeadyBrain (Central Intelligence)\n",
    "\n",
    "Pre-response processing pipeline with comprehensive system awareness.\n",
    "\n",
    "### Integration\n",
    "- **LENS** monitoring -> Real-time system state\n",
    "- **MEMORY** storage -> Persistent knowledge\n",
    "- **CONDUCTOR** orchestration -> Task routing\n",
    "\n",
    "### Processing Pipeline\n",
    "```\n",
    "Input -> 1. Gather Context (LENS + MEMORY)\n",
    "      -> 2. Analyze Patterns (History, Embeddings)\n",
    "      -> 3. Route Decision (CONDUCTOR + Registry)\n",
    "      -> 4. Execute with Monitoring (Parallel + Cached)\n",
    "      -> 5. Post-Process (Audit, Checkpoint, Memory Update)\n",
    "```\n",
    "\n",
    "### Key Features\n",
    "- `ProcessingContext` dataclass for structured state\n",
    "- Thread pool executor for parallel processing\n",
    "- LRU caching + SHA-256 content hashing\n",
    "- Optional `psutil` + `requests` for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "brain-subsystems"},
   "outputs": [],
   "source": [
    "def get_subsystems():\n",
    "    try:\n",
    "        return requests.get(f'{MANAGER_URL}/api/subsystems', timeout=5).json()\n",
    "    except:\n",
    "        return {'error': 'Unavailable'}\n",
    "\n",
    "subsystems = get_subsystems()\n",
    "print('=== HCFullPipeline Subsystems ===')\n",
    "print(json.dumps(subsystems, indent=2, default=str)[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-vi"},
   "source": [
    "---\n",
    "## VI. AI Node Intelligence\n",
    "\n",
    "| Node | Alias | Role | Tool | Triggers |\n",
    "|------|-------|------|------|----------|\n",
    "| **JULES** | The Hyper-Surgeon | Code optimization | `goose` | `optimization` |\n",
    "| **OBSERVER** | The Natural Observer | Monitoring | `observer_daemon` | `monitor` |\n",
    "| **BUILDER** | The Constructor | Project optimization | `hydrator` | `new_project` |\n",
    "| **ATLAS** | The Auto-Archivist | Documentation | `auto_doc` | `documentation` |\n",
    "| **PYTHIA** | The Oracle | ML Inference | `HuggingFace_Tool` | `huggingface`, `predict`, `ask_oracle` |\n",
    "\n",
    "### Node Lifecycle\n",
    "```\n",
    "STANDBY --[trigger]--> ACTIVE --[complete]--> AVAILABLE\n",
    "                                                  |\n",
    "STANDBY <-----------[deactivate]------------------+\n",
    "```\n",
    "\n",
    "### PYTHIA (HuggingFace Integration)\n",
    "- Tool: `HeadyAcademy/Tools/HuggingFace_Tool.py`\n",
    "- Pipeline: `transformers.pipeline()` for text generation, sentiment\n",
    "- Default Model: GPT-2 (override with `--model`)\n",
    "- Output: JSON to `HeadyAcademy/Model_Output/hf_*.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "nodes-status"},
   "outputs": [],
   "source": [
    "def get_nodes():\n",
    "    try:\n",
    "        return requests.get(f'{MANAGER_URL}/api/nodes', timeout=5).json()\n",
    "    except:\n",
    "        return {'error': 'Unavailable'}\n",
    "\n",
    "def activate_production():\n",
    "    try:\n",
    "        return requests.post(f'{MANAGER_URL}/api/system/production', timeout=10).json()\n",
    "    except:\n",
    "        return {'error': 'Unavailable'}\n",
    "\n",
    "nodes = get_nodes()\n",
    "if 'nodes' in nodes:\n",
    "    print(f\"Total: {nodes['total']} | Active: {nodes['active']}\\n\")\n",
    "    rows = [[n.get('id',''), n.get('role',''), n.get('status',''),\n",
    "             n.get('primary_tool',''), str(n.get('last_invoked','never'))[:19]]\n",
    "            for n in nodes['nodes']]\n",
    "    print(tabulate(rows, headers=['Node','Role','Status','Tool','Last Invoked'], tablefmt='grid'))\n",
    "else:\n",
    "    print(json.dumps(nodes, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-vii"},
   "source": [
    "---\n",
    "## VII. HCFullPipeline & Subsystems\n",
    "\n",
    "### Pipeline Stages\n",
    "```\n",
    "DISCOVERY -> ANALYSIS -> BUILD -> TEST -> CHECKPOINT -> DEPLOY\n",
    "              Circuit Breakers + Retry Logic\n",
    "```\n",
    "\n",
    "### Subsystem APIs\n",
    "| Subsystem | API Prefix | Function |\n",
    "|-----------|------------|----------|\n",
    "| Supervisor | `/api/supervisor/*` | Agent routing, task delegation |\n",
    "| Brain | `/api/brain/*` | Auto-tuning, governance |\n",
    "| Checkpoint | `/api/checkpoint/*` | State analysis, recommendations |\n",
    "| Readiness | `/api/readiness/*` | HTTP/DB probe evaluation |\n",
    "| Health | `/api/health-checks/*` | Cron monitoring |\n",
    "| Pipeline | `/api/pipeline/*` | Run management, history |\n",
    "| Claude | `/api/pipeline/claude/*` | AI execution, code analysis |\n",
    "\n",
    "### HCAutoBuild Scoring\n",
    "| Component | Weight |\n",
    "|-----------|--------|\n",
    "| Health Check | 40% |\n",
    "| Build Status | 30% |\n",
    "| Git Cleanliness | 15% |\n",
    "| Recent Activity | 15% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "pipeline-status"},
   "outputs": [],
   "source": [
    "def get_pipeline_config():\n",
    "    try:\n",
    "        return requests.get(f'{MANAGER_URL}/api/pipeline/config', timeout=5).json()\n",
    "    except:\n",
    "        return {'error': 'Unavailable'}\n",
    "\n",
    "def get_pipeline_state():\n",
    "    try:\n",
    "        return requests.get(f'{MANAGER_URL}/api/pipeline/state', timeout=5).json()\n",
    "    except:\n",
    "        return {'error': 'Unavailable'}\n",
    "\n",
    "print('=== Pipeline Config ===')\n",
    "print(json.dumps(get_pipeline_config(), indent=2, default=str)[:2000])\n",
    "\n",
    "print('\\n=== Pipeline State ===')\n",
    "print(json.dumps(get_pipeline_state(), indent=2, default=str)[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-viii"},
   "source": [
    "---\n",
    "## VIII. Data Schema & Storage Architecture\n",
    "\n",
    "4-layer data model defined in `configs/data-schema.yaml`:\n",
    "\n",
    "### Data Layers\n",
    "| Layer | Name | Format | Retention |\n",
    "|-------|------|--------|-----------|\n",
    "| L0 | Raw Ingestion | json-lines | 30 days |\n",
    "| L1 | Cleaned & Normalized | structured-json | 90 days |\n",
    "| L2 | Feature / Concept | json + vector(1536) | 365 days |\n",
    "| L3 | Application Views | materialized views | as-needed |\n",
    "\n",
    "### PostgreSQL Tables\n",
    "| Table | Purpose |\n",
    "|-------|---------|\n",
    "| `pipeline_runs` | Execution history |\n",
    "| `concepts` | Extracted concepts + embeddings |\n",
    "| `health_checks` | Node health results |\n",
    "| `checkpoint_records` | Checkpoint analysis |\n",
    "| `audit_events` | Immutable audit trail |\n",
    "| `cost_tracking` | Per-run/agent costs |\n",
    "\n",
    "### Ephemeral\n",
    "- In-Memory Cache: `Map()`, 5min TTL, 10K max\n",
    "- Task Queues: In-process (Redis at scale)\n",
    "- Temp Files: `/tmp/heady/`, 1hr TTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "data-schema"},
   "outputs": [],
   "source": [
    "schema_path = HEADY_ROOT / 'configs' / 'data-schema.yaml'\n",
    "\n",
    "if schema_path.exists():\n",
    "    with open(schema_path) as f:\n",
    "        schema = yaml.safe_load(f)\n",
    "\n",
    "    print(f\"Schema Version: {schema.get('version', 'unknown')}\\n\")\n",
    "\n",
    "    print('=== Data Layers ===')\n",
    "    layers = schema.get('dataLayers', {})\n",
    "    rows = [[lid, l.get('name',''), l.get('format',''), l.get('retention',''),\n",
    "             len(l.get('transforms',[]))] for lid, l in layers.items()]\n",
    "    print(tabulate(rows, headers=['ID','Name','Format','Retention','Transforms'], tablefmt='grid'))\n",
    "\n",
    "    print('\\n=== PostgreSQL Tables ===')\n",
    "    tables = schema.get('persistentStorage',{}).get('relational',{}).get('schemas',[])\n",
    "    rows = [[t.get('name',''), t.get('description','')[:50], len(t.get('fields',[])),\n",
    "             ', '.join(f['name'] for f in t.get('fields',[])[:4])] for t in tables]\n",
    "    print(tabulate(rows, headers=['Table','Description','Fields','Key Columns'], tablefmt='grid'))\n",
    "else:\n",
    "    print('data-schema.yaml not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-ix"},
   "source": [
    "---\n",
    "## IX. Cloud Layers & Deployment\n",
    "\n",
    "### 5 Configurable Layers\n",
    "| Layer ID | Name | Endpoint | Color |\n",
    "|----------|------|----------|-------|\n",
    "| `local` | Local Dev | localhost:3300 | Green |\n",
    "| `cloud-me` | Cloud HeadyMe | heady-manager-headyme.onrender.com | Cyan |\n",
    "| `cloud-sys` | Cloud HeadySystems | heady-manager-headysystems.onrender.com | Magenta |\n",
    "| `cloud-conn` | Cloud HeadyConnection | heady-manager-headyconnection.onrender.com | Yellow |\n",
    "| `hybrid` | Hybrid Local+Cloud | .env.hybrid | White |\n",
    "\n",
    "### Render.com Config\n",
    "- Build: `npm install && npm run build --prefix frontend`\n",
    "- Start: `node heady-manager.js`\n",
    "- Env: PORT, NODE_ENV, DATABASE_URL, HEADY_API_KEY, HF_TOKEN\n",
    "- Node Flags: JULES_ENABLED, OBSERVER_ENABLED, BUILDER_ENABLED, ATLAS_ENABLED\n",
    "\n",
    "### Git Sync Targets\n",
    "| Remote | URL |\n",
    "|--------|-----|\n",
    "| heady-me | git@github.com:HeadyMe/Heady.git |\n",
    "| origin | git@github.com:HeadySystems/Heady.git |\n",
    "| connection | https://github.com/HeadySystems/HeadyConnection.git |\n",
    "| sandbox | git@github.com:HeadySystems/sandbox.git |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "layer-health"},
   "outputs": [],
   "source": [
    "CLOUD_ENDPOINTS = {\n",
    "    'local': 'http://localhost:3300',\n",
    "    'cloud-me': 'https://heady-manager-headyme.onrender.com',\n",
    "    'cloud-sys': 'https://heady-manager-headysystems.onrender.com',\n",
    "    'cloud-conn': 'https://heady-manager-headyconnection.onrender.com',\n",
    "}\n",
    "\n",
    "print('=== Layer Health Check ===')\n",
    "rows = []\n",
    "for lid, endpoint in CLOUD_ENDPOINTS.items():\n",
    "    try:\n",
    "        resp = requests.get(f'{endpoint}/api/health', timeout=8)\n",
    "        if resp.status_code == 200:\n",
    "            rows.append([lid, endpoint[:50], 'ONLINE', f'{resp.elapsed.total_seconds():.2f}s'])\n",
    "        else:\n",
    "            rows.append([lid, endpoint[:50], f'HTTP {resp.status_code}', '-'])\n",
    "    except requests.ConnectionError:\n",
    "        rows.append([lid, endpoint[:50], 'OFFLINE', '-'])\n",
    "    except requests.Timeout:\n",
    "        rows.append([lid, endpoint[:50], 'TIMEOUT', '>8s'])\n",
    "\n",
    "print(tabulate(rows, headers=['Layer','Endpoint','Status','Latency'], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-x"},
   "source": [
    "---\n",
    "## X. API Reference & Live Testing\n",
    "\n",
    "### Complete Endpoint Map\n",
    "\n",
    "| Method | Endpoint | Description |\n",
    "|--------|----------|-------------|\n",
    "| GET | `/api/health` | System health + uptime + memory |\n",
    "| GET | `/api/pulse` | Quick pulse with layer info |\n",
    "| GET | `/api/registry` | Component registry |\n",
    "| GET | `/api/maid/config` | HeadyMaid configuration |\n",
    "| GET | `/api/maid/inventory` | File inventory |\n",
    "| POST | `/api/conductor/orchestrate` | Route request to conductor |\n",
    "| GET | `/api/conductor/summary` | System summary |\n",
    "| GET | `/api/conductor/health` | Conductor health |\n",
    "| GET | `/api/conductor/query?q=` | Query conductor |\n",
    "| POST | `/api/conductor/workflow` | Execute workflow |\n",
    "| POST | `/api/conductor/node` | Invoke specific node |\n",
    "| GET | `/api/layer` | Active layer info |\n",
    "| POST | `/api/layer/switch` | Switch active layer |\n",
    "| GET | `/api/nodes` | All node statuses |\n",
    "| GET | `/api/nodes/:id` | Single node status |\n",
    "| POST | `/api/nodes/:id/activate` | Activate node |\n",
    "| POST | `/api/nodes/:id/deactivate` | Deactivate node |\n",
    "| POST | `/api/nodes/activate-all` | Activate all nodes |\n",
    "| GET | `/api/system/status` | Full system dashboard |\n",
    "| POST | `/api/system/production` | Production mode activation |\n",
    "| GET | `/api/pipeline/config` | Pipeline config |\n",
    "| GET | `/api/pipeline/dag` | Stage DAG |\n",
    "| POST | `/api/pipeline/run` | Trigger pipeline run |\n",
    "| GET | `/api/pipeline/state` | Current run state |\n",
    "| GET | `/api/pipeline/state/full` | Full verbose state |\n",
    "| GET | `/api/pipeline/history` | Run history |\n",
    "| GET | `/api/pipeline/circuit-breakers` | Circuit breaker status |\n",
    "| POST | `/api/pipeline/claude` | Claude Code ad-hoc execution |\n",
    "| POST | `/api/pipeline/claude/analyze` | Code analysis |\n",
    "| POST | `/api/pipeline/claude/security` | Security audit |\n",
    "| GET | `/api/pipeline/log?limit=` | Pipeline log entries |\n",
    "| GET | `/api/supervisor/status` | Supervisor status |\n",
    "| POST | `/api/supervisor/route` | Route task to agent |\n",
    "| GET | `/api/brain/status` | Brain status |\n",
    "| POST | `/api/brain/tune` | Auto-tune system |\n",
    "| POST | `/api/brain/governance-check` | Governance validation |\n",
    "| POST | `/api/brain/evaluate-pattern` | Pattern evaluation |\n",
    "| GET | `/api/readiness/evaluate` | Readiness evaluation |\n",
    "| GET | `/api/readiness/history` | Readiness history |\n",
    "| GET | `/api/health-checks/snapshot` | Health snapshot |\n",
    "| POST | `/api/health-checks/run` | Run all health checks |\n",
    "| GET | `/api/health-checks/history` | Health check history |\n",
    "| POST | `/api/checkpoint/analyze` | Analyze checkpoint |\n",
    "| GET | `/api/checkpoint/records` | Checkpoint records |\n",
    "| GET | `/api/agents/claude-code/status` | Claude Code agent |\n",
    "| GET | `/api/subsystems` | Combined subsystem overview |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "api-client"},
   "outputs": [],
   "source": [
    "class HeadyAPIClient:\n",
    "    \"\"\"Unified client for all Heady System APIs.\"\"\"\n",
    "\n",
    "    def __init__(self, base_url='http://localhost:3300'):\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({'Content-Type': 'application/json'})\n",
    "\n",
    "    def get(self, endpoint, **kw):\n",
    "        try:\n",
    "            return self.session.get(f'{self.base_url}{endpoint}', timeout=10, **kw).json()\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "\n",
    "    def post(self, endpoint, data=None, **kw):\n",
    "        try:\n",
    "            return self.session.post(f'{self.base_url}{endpoint}', json=data, timeout=30, **kw).json()\n",
    "        except Exception as e:\n",
    "            return {'error': str(e)}\n",
    "\n",
    "    def health(self): return self.get('/api/health')\n",
    "    def pulse(self): return self.get('/api/pulse')\n",
    "    def nodes(self): return self.get('/api/nodes')\n",
    "    def system_status(self): return self.get('/api/system/status')\n",
    "    def subsystems(self): return self.get('/api/subsystems')\n",
    "    def pipeline_state(self): return self.get('/api/pipeline/state')\n",
    "    def layer(self): return self.get('/api/layer')\n",
    "    def orchestrate(self, text): return self.post('/api/conductor/orchestrate', {'request': text})\n",
    "    def activate_production(self): return self.post('/api/system/production')\n",
    "    def run_pipeline(self): return self.post('/api/pipeline/run')\n",
    "    def claude_execute(self, prompt, budget=0.25):\n",
    "        return self.post('/api/pipeline/claude', {'prompt': prompt, 'maxBudgetUsd': budget})\n",
    "\n",
    "api = HeadyAPIClient(MANAGER_URL)\n",
    "print('=== Quick Health ===')\n",
    "print(json.dumps(api.health(), indent=2, default=str)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "api-batch-test"},
   "outputs": [],
   "source": [
    "ENDPOINTS = [\n",
    "    '/api/health', '/api/pulse', '/api/registry', '/api/layer',\n",
    "    '/api/nodes', '/api/system/status', '/api/subsystems',\n",
    "    '/api/pipeline/config', '/api/pipeline/state', '/api/pipeline/history',\n",
    "    '/api/pipeline/circuit-breakers', '/api/supervisor/status',\n",
    "    '/api/brain/status', '/api/readiness/history',\n",
    "    '/api/health-checks/snapshot', '/api/health-checks/history',\n",
    "    '/api/checkpoint/records', '/api/maid/config',\n",
    "]\n",
    "\n",
    "print('=== Batch Endpoint Verification ===')\n",
    "rows, ok = [], 0\n",
    "for ep in ENDPOINTS:\n",
    "    try:\n",
    "        r = requests.get(f'{MANAGER_URL}{ep}', timeout=8)\n",
    "        if r.status_code == 200: ok += 1\n",
    "        rows.append([ep, str(r.status_code), f'{r.elapsed.total_seconds():.3f}s', f'{len(r.content)} B'])\n",
    "    except requests.ConnectionError:\n",
    "        rows.append([ep, 'OFFLINE', '-', '-'])\n",
    "    except Exception as e:\n",
    "        rows.append([ep, 'ERROR', '-', str(e)[:30]])\n",
    "\n",
    "print(tabulate(rows, headers=['Endpoint','Status','Latency','Size'], tablefmt='grid'))\n",
    "print(f'\\nResult: {ok}/{len(ENDPOINTS)} endpoints OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "section-xi"},
   "source": [
    "---\n",
    "## XI. Sacred Geometry Quiz & Flashcards\n",
    "\n",
    "Following the **Heady Documentation Protocol (Quiz Protocol)**, this section provides review flashcards covering the entire system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "flashcards"},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "FLASHCARDS = [\n",
    "    {'cat': 'Architecture', 'q': 'What is the core philosophy behind Heady Systems?',\n",
    "     'a': 'Deterministic Behavior - identical outputs from identical inputs, enabling reproducible builds, checkpoint recovery, audit integrity, and intelligent routing.'},\n",
    "    {'cat': 'Architecture', 'q': 'What two runtime environments form the hybrid architecture?',\n",
    "     'a': 'Node.js (HeadyManager, Express, MCP) and Python (HeadyConductor, HeadyBrain, AI Nodes).'},\n",
    "    {'cat': 'Architecture', 'q': 'What port does HeadyManager listen on by default?',\n",
    "     'a': 'Port 3300 (configurable via PORT env var).'},\n",
    "    {'cat': 'Architecture', 'q': 'True or False: Heady Systems uses Sacred Geometry principles.',\n",
    "     'a': 'True. The patented Sacred Geometry architecture guides organic systems and breathing interfaces.'},\n",
    "    {'cat': 'AI Nodes', 'q': 'Name all 5 AI Nodes and their aliases.',\n",
    "     'a': 'JULES (Hyper-Surgeon), OBSERVER (Natural Observer), BUILDER (Constructor), ATLAS (Auto-Archivist), PYTHIA (Oracle).'},\n",
    "    {'cat': 'AI Nodes', 'q': 'Which node handles HuggingFace ML inference?',\n",
    "     'a': 'PYTHIA (The Oracle), using HuggingFace_Tool.py with transformers pipeline.'},\n",
    "    {'cat': 'AI Nodes', 'q': 'What tool does JULES use for code optimization?',\n",
    "     'a': 'The goose tool - Python-based optimizer for unused imports, code quality, performance, security.'},\n",
    "    {'cat': 'AI Nodes', 'q': 'What are the three node lifecycle states?',\n",
    "     'a': 'STANDBY -> ACTIVE (on trigger) -> AVAILABLE (on completion). Can deactivate back to STANDBY.'},\n",
    "    {'cat': 'Pipeline', 'q': 'What are the 6 HCFullPipeline stages?',\n",
    "     'a': 'DISCOVERY -> ANALYSIS -> BUILD -> TEST -> CHECKPOINT -> DEPLOY, with circuit breakers.'},\n",
    "    {'cat': 'Pipeline', 'q': 'What triggers a checkpoint in HCAutoBuild?',\n",
    "     'a': '100% functionality: all health checks pass, all builds succeed, git has changes, recent activity.'},\n",
    "    {'cat': 'Pipeline', 'q': 'What 4 components make up the HCAutoBuild score?',\n",
    "     'a': 'Health Check (40%), Build Status (30%), Git Cleanliness (15%), Recent Activity (15%).'},\n",
    "    {'cat': 'Pipeline', 'q': 'What 5 subsystems does HCFullPipeline initialize?',\n",
    "     'a': 'Supervisor, SystemBrain, CheckpointAnalyzer, ReadinessEvaluator, HealthCheckRunner.'},\n",
    "    {'cat': 'Data', 'q': 'Name the 4 data layers and retention.',\n",
    "     'a': 'L0 Raw (30d), L1 Cleaned (90d), L2 Feature+embeddings (365d), L3 Views (as-needed).'},\n",
    "    {'cat': 'Data', 'q': 'What vector dimension for concept embeddings?',\n",
    "     'a': '1536 dimensions (vector(1536) in PostgreSQL).'},\n",
    "    {'cat': 'Data', 'q': 'What is the HeadyManager in-memory cache TTL?',\n",
    "     'a': '5 minutes (300,000ms), max 10,000 entries using Node.js Map().'},\n",
    "    {'cat': 'Deployment', 'q': 'Name all 5 configurable cloud layers.',\n",
    "     'a': 'local, cloud-me (HeadyMe), cloud-sys (HeadySystems), cloud-conn (HeadyConnection), hybrid.'},\n",
    "    {'cat': 'Deployment', 'q': 'What deployment platform does Heady use?',\n",
    "     'a': 'Render.com Blueprint (render.yaml) with Node.js web service.'},\n",
    "    {'cat': 'Deployment', 'q': 'How many git remotes does HeadySync push to?',\n",
    "     'a': '4 remotes: heady-me, origin/heady-sys, connection, sandbox.'},\n",
    "    {'cat': 'APIs', 'q': 'What endpoint activates full production mode?',\n",
    "     'a': 'POST /api/system/production - activates all nodes, tools, workflows, services.'},\n",
    "    {'cat': 'APIs', 'q': 'What rate limit is applied to /api/ endpoints?',\n",
    "     'a': '1000 requests per 15-minute window per IP (express-rate-limit).'},\n",
    "    {'cat': 'Conductor', 'q': 'What 4 core components does HeadyConductor integrate?',\n",
    "     'a': 'HeadyRegistry, HeadyLens, HeadyMemory, HeadyBrain.'},\n",
    "    {'cat': 'Conductor', 'q': 'How does Conductor calculate confidence?',\n",
    "     'a': 'Slash match=0.95, name=0.85, trigger=0.85, role=0.80, keywords=0.75, then x1.1 boost (max 1.0).'},\n",
    "    {'cat': 'Security', 'q': 'What security middleware does HeadyManager use?',\n",
    "     'a': 'Helmet, CORS, express-rate-limit, timing-safe API key validation, compression.'},\n",
    "    {'cat': 'Security', 'q': 'How many checks does the Intelligence Verifier run?',\n",
    "     'a': '16 checks: registry, memory, checkpoint, context, schema, codemap, manager, MCP, orchestrator, squash-merge, routing, governance, audit, validation, filesystem, git.'},\n",
    "]\n",
    "\n",
    "grouped = defaultdict(list)\n",
    "for c in FLASHCARDS:\n",
    "    grouped[c['cat']].append(c)\n",
    "\n",
    "print(f'Total Flashcards: {len(FLASHCARDS)}')\n",
    "print(f\"Categories: {', '.join(grouped.keys())}\\n\")\n",
    "\n",
    "for cat, cards in grouped.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f'  {cat} ({len(cards)} cards)')\n",
    "    print(f\"{'='*60}\")\n",
    "    for i, c in enumerate(cards, 1):\n",
    "        print(f\"\\n  Q{i}: {c['q']}\")\n",
    "        print(f\"  A{i}: {c['a']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "quiz-interactive"},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def run_quiz(cards, num=5):\n",
    "    \"\"\"Interactive quiz from the flashcard deck.\"\"\"\n",
    "    selected = random.sample(cards, min(num, len(cards)))\n",
    "    score = 0\n",
    "    print('\\n' + '='*60)\n",
    "    print('  HEADY SYSTEMS QUIZ')\n",
    "    print('  Answer each question, then rate yourself 1-3.')\n",
    "    print('='*60)\n",
    "\n",
    "    for i, c in enumerate(selected, 1):\n",
    "        print(f\"\\n--- Q{i}/{len(selected)} [{c['cat']}] ---\")\n",
    "        print(f\"Q: {c['q']}\")\n",
    "        input('\\n[Press Enter to reveal answer]')\n",
    "        print(f\"A: {c['a']}\")\n",
    "        try:\n",
    "            r = int(input('Self-rate (1=Wrong, 2=Partial, 3=Correct): '))\n",
    "            score += {3: 1, 2: 0.5}.get(r, 0)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    pct = (score / len(selected)) * 100\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f'  SCORE: {score}/{len(selected)} ({pct:.0f}%)')\n",
    "    grade = 'Sacred Geometry Master' if pct >= 90 else 'Journeyman' if pct >= 70 else 'Apprentice'\n",
    "    print(f'  RANK: {grade}')\n",
    "    print('='*60)\n",
    "\n",
    "# Uncomment to run:\n",
    "# run_quiz(FLASHCARDS, num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"id": "project-tree"},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Project File Tree Summary\n",
    "# ==============================================================================\n",
    "\n",
    "KEY_PATHS = {\n",
    "    'heady-manager.js': 'Node.js MCP Server & Admin API (port 3300)',\n",
    "    'package.json': 'Root dependencies & scripts',\n",
    "    'render.yaml': 'Render.com deployment blueprint',\n",
    "    'HeadyAcademy/HeadyConductor.py': 'Python orchestration layer',\n",
    "    'HeadyAcademy/HeadyBrain.py': 'Central intelligence coordinator',\n",
    "    'HeadyAcademy/HeadyRegistry.py': 'Component/workflow/tool registry',\n",
    "    'HeadyAcademy/HeadyLens.py': 'Real-time monitoring',\n",
    "    'HeadyAcademy/HeadyMemory.py': 'Persistent memory storage',\n",
    "    'HeadyAcademy/Tools/HuggingFace_Tool.py': 'PYTHIA ML inference tool',\n",
    "    'src/hc_pipeline.js': 'HCFullPipeline orchestrator',\n",
    "    'src/hc_claude_agent.js': 'Claude Code integration',\n",
    "    'src/heady_maid.js': 'File observability & inventory',\n",
    "    'src/heady_intelligence_verifier.js': '16-check pre-response validator',\n",
    "    'configs/data-schema.yaml': '4-layer data model definition',\n",
    "    'configs/governance-policies.yaml': 'Governance rules',\n",
    "    'scripts/heady-layers.json': 'Cloud layer definitions',\n",
    "    'scripts/Heady-Sync.ps1': 'Multi-remote git sync',\n",
    "    'frontend/src/App.js': 'React frontend entry',\n",
    "    'public/index.html': 'Static HTML entry',\n",
    "    '.heady/registry.json': 'Production node/tool/workflow registry',\n",
    "    'packages/hc-brain/src/index.js': 'SystemBrain subsystem',\n",
    "    'packages/hc-supervisor/src/index.js': 'Supervisor agent router',\n",
    "    'packages/hc-checkpoint/src/index.js': 'CheckpointAnalyzer',\n",
    "    'packages/hc-readiness/src/index.js': 'ReadinessEvaluator',\n",
    "    'packages/hc-health/src/index.js': 'HealthCheckRunner',\n",
    "}\n",
    "\n",
    "print('=== Key Project Files ===')\n",
    "rows = []\n",
    "for path, desc in KEY_PATHS.items():\n",
    "    full = HEADY_ROOT / path\n",
    "    exists = full.exists()\n",
    "    size = f'{full.stat().st_size/1024:.1f}KB' if exists else '-'\n",
    "    rows.append([path, 'OK' if exists else 'MISSING', size, desc[:45]])\n",
    "\n",
    "print(tabulate(rows, headers=['Path', 'Status', 'Size', 'Description'], tablefmt='grid'))\n",
    "\n",
    "found = sum(1 for p in KEY_PATHS if (HEADY_ROOT / p).exists())\n",
    "print(f'\\nFile Coverage: {found}/{len(KEY_PATHS)} ({found/len(KEY_PATHS)*100:.0f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {"id": "footer"},
   "source": [
    "---\n",
    "\n",
    "## Sacred Geometry :: Organic Systems :: Breathing Interfaces\n",
    "\n",
    "**Heady Systems v2.0.0** | [HeadySystems/Heady](https://github.com/HeadySystems/Heady)\n",
    "\n",
    "This notebook is the living documentation for the entire Heady ecosystem. Run it locally or in Google Colab to interact with all system components.\n",
    "\n",
    "---\n",
    "*Generated by Heady Systems | Sacred Geometry Architecture*"
   ]
  }
 ]
}
