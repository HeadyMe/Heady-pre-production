{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JULES GPU Node — Code Optimization & Quality Analysis\n",
    "\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║  ∞ SACRED GEOMETRY ∞  Organic Systems · Breathing Interfaces    ║\n",
    "║  NODE: JULES Colab Pro+ GPU                                     ║\n",
    "║  PURPOSE: Code optimization, quality analysis, refactoring      ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "```\n",
    "\n",
    "**Capabilities:**\n",
    "- Code quality analysis via ML models\n",
    "- Refactoring suggestions using code embeddings\n",
    "- Complexity scoring & optimization recommendations\n",
    "- Code similarity / duplicate detection\n",
    "- Security vulnerability pattern matching\n",
    "\n",
    "**Branded domains only:** headysystems.com | headycloud.com | headyconnection.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install dependencies + verify GPU\n",
    "!pip install -q transformers accelerate sentence-transformers fastapi uvicorn pyngrok httpx tree-sitter\n",
    "\n",
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('WARNING: No GPU — will run on CPU (slower)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration\n",
    "import os\n",
    "\n",
    "HEADY_CONFIG = {\n",
    "    'node_id': 'jules-gpu',\n",
    "    'node_role': 'code-optimizer',\n",
    "    'port': 5002,\n",
    "    'cloud_layers': {\n",
    "        'headysystems': 'https://headyio.com',\n",
    "        'headyme': 'https://headycloud.com',\n",
    "        'headyconnection': 'https://headyconnection.com',\n",
    "    },\n",
    "    'registration_endpoints': [\n",
    "        'https://headyio.com/api/nodes/register',\n",
    "        'https://headycloud.com/api/nodes/register',\n",
    "        'https://headyconnection.com/api/nodes/register',\n",
    "    ],\n",
    "    'capabilities': ['optimization', 'code_quality', 'refactor', 'security_scan', 'complexity_analysis'],\n",
    "}\n",
    "\n",
    "SUPPORTED_TASKS = {\n",
    "    'optimization': 'Suggest performance optimizations for code',\n",
    "    'code_quality': 'Analyze code quality and assign a score',\n",
    "    'refactor': 'Suggest refactoring improvements',\n",
    "    'security_scan': 'Detect common security vulnerability patterns',\n",
    "    'complexity_analysis': 'Compute complexity metrics',\n",
    "    'similarity': 'Find similar/duplicate code blocks',\n",
    "}\n",
    "\n",
    "print(f'JULES Node configured')\n",
    "print(f'Capabilities: {HEADY_CONFIG[\"capabilities\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load models on GPU\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json, time, re\n",
    "from datetime import datetime\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Code embeddings model — for similarity and quality analysis\n",
    "print('Loading code embedding model...')\n",
    "code_embedder = SentenceTransformer('microsoft/codebert-base', device=device)\n",
    "print('CodeBERT embeddings ready')\n",
    "\n",
    "# Text model for generating optimization suggestions\n",
    "print('Loading code analysis model...')\n",
    "code_analyzer = pipeline('text-generation', model='TinyLlama/TinyLlama-1.1B-Chat-v1.0', device=0 if torch.cuda.is_available() else -1, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)\n",
    "print('Code analysis ready')\n",
    "\n",
    "print(f'\\nAll JULES models loaded on {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU Memory used: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Core JULES functions\n",
    "\n",
    "# Security vulnerability patterns\n",
    "VULN_PATTERNS = {\n",
    "    'sql_injection': [r'\\$\\{.*\\}.*(?:SELECT|INSERT|UPDATE|DELETE|DROP)', r'f[\"\\'].*(?:SELECT|INSERT|UPDATE|DELETE)', r'\\+.*(?:SELECT|INSERT|UPDATE|DELETE)'],\n",
    "    'xss': [r'innerHTML\\s*=', r'document\\.write\\(', r'\\$\\(.*\\)\\.html\\(', r'dangerouslySetInnerHTML'],\n",
    "    'hardcoded_secret': [r'(?:password|secret|api_key|token)\\s*=\\s*[\"\\'][^\"\\']+(\\w{8,})', r'(?:AWS|AZURE|GCP)_(?:SECRET|KEY)\\s*='],\n",
    "    'eval_usage': [r'eval\\(', r'exec\\(', r'Function\\('],\n",
    "    'path_traversal': [r'\\.\\./\\.\\./'],\n",
    "    'insecure_random': [r'Math\\.random\\(\\)', r'random\\.random\\(\\)'],\n",
    "    'no_input_validation': [r'req\\.(?:body|params|query)\\.\\w+(?!.*(?:valid|sanitiz|escap|check))'],\n",
    "}\n",
    "\n",
    "# Code smell patterns\n",
    "CODE_SMELLS = {\n",
    "    'long_function': {'pattern': r'(?:function|def|=>).*\\{', 'threshold': 50, 'unit': 'lines'},\n",
    "    'deep_nesting': {'pattern': r'^(\\s{16,}|\\t{4,})', 'severity': 'warning'},\n",
    "    'magic_numbers': {'pattern': r'(?<![\\w.])\\d{2,}(?![\\w.])', 'severity': 'info'},\n",
    "    'god_class': {'threshold': 500, 'unit': 'lines'},\n",
    "    'duplicate_code': {'min_similarity': 0.85},\n",
    "}\n",
    "\n",
    "def analyze_code_quality(code, language='javascript'):\n",
    "    \"\"\"Comprehensive code quality analysis\"\"\"\n",
    "    start = time.time()\n",
    "    lines = code.split('\\n')\n",
    "    total_lines = len(lines)\n",
    "    code_lines = len([l for l in lines if l.strip() and not l.strip().startswith(('/', '#', '*', '<!--'))])\n",
    "    comment_lines = len([l for l in lines if l.strip().startswith(('/', '#', '*', '<!--'))])\n",
    "\n",
    "    # Complexity indicators\n",
    "    nesting_depths = []\n",
    "    for line in lines:\n",
    "        stripped = line.rstrip()\n",
    "        if stripped:\n",
    "            indent = len(stripped) - len(stripped.lstrip())\n",
    "            nesting_depths.append(indent)\n",
    "    max_nesting = max(nesting_depths) if nesting_depths else 0\n",
    "    avg_nesting = np.mean(nesting_depths) if nesting_depths else 0\n",
    "\n",
    "    # Function count\n",
    "    func_patterns = [r'function\\s+\\w+', r'\\w+\\s*=\\s*(?:async\\s+)?(?:function|\\()', r'def\\s+\\w+', r'=>']\n",
    "    func_count = sum(len(re.findall(p, code)) for p in func_patterns)\n",
    "\n",
    "    # Security scan\n",
    "    vulns = []\n",
    "    for vuln_type, patterns in VULN_PATTERNS.items():\n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, code, re.IGNORECASE | re.MULTILINE)\n",
    "            if matches:\n",
    "                vulns.append({'type': vuln_type, 'count': len(matches), 'severity': 'high' if vuln_type in ('sql_injection', 'hardcoded_secret') else 'medium'})\n",
    "\n",
    "    # Quality score (0-100)\n",
    "    score = 100\n",
    "    if total_lines > 500: score -= 10\n",
    "    if max_nesting > 32: score -= 15\n",
    "    elif max_nesting > 16: score -= 8\n",
    "    if comment_lines / max(code_lines, 1) < 0.1: score -= 10\n",
    "    if func_count > 0 and code_lines / func_count > 50: score -= 10\n",
    "    score -= len(vulns) * 8\n",
    "    score = max(0, min(100, score))\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return {\n",
    "        'quality_score': score,\n",
    "        'metrics': {\n",
    "            'total_lines': total_lines,\n",
    "            'code_lines': code_lines,\n",
    "            'comment_lines': comment_lines,\n",
    "            'comment_ratio': round(comment_lines / max(code_lines, 1), 3),\n",
    "            'max_nesting_depth': max_nesting,\n",
    "            'avg_nesting_depth': round(avg_nesting, 2),\n",
    "            'function_count': func_count,\n",
    "            'avg_function_length': round(code_lines / max(func_count, 1), 1),\n",
    "        },\n",
    "        'vulnerabilities': vulns,\n",
    "        'vulnerability_count': len(vulns),\n",
    "        'language': language,\n",
    "        'latency_ms': round(elapsed * 1000),\n",
    "        'device': device,\n",
    "    }\n",
    "\n",
    "def find_similar_code(code_blocks):\n",
    "    \"\"\"Find duplicate/similar code blocks using CodeBERT embeddings\"\"\"\n",
    "    start = time.time()\n",
    "    embeddings = code_embedder.encode(code_blocks)\n",
    "    sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(len(code_blocks)):\n",
    "        for j in range(i + 1, len(code_blocks)):\n",
    "            if sim_matrix[i][j] > 0.85:\n",
    "                pairs.append({\n",
    "                    'block_a': i,\n",
    "                    'block_b': j,\n",
    "                    'similarity': round(float(sim_matrix[i][j]), 4),\n",
    "                    'recommendation': 'Extract common logic into shared function',\n",
    "                })\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return {\n",
    "        'total_blocks': len(code_blocks),\n",
    "        'similar_pairs': pairs,\n",
    "        'duplicate_count': len(pairs),\n",
    "        'latency_ms': round(elapsed * 1000),\n",
    "        'device': device,\n",
    "    }\n",
    "\n",
    "def suggest_refactoring(code, language='javascript'):\n",
    "    \"\"\"Generate refactoring suggestions using LLM\"\"\"\n",
    "    start = time.time()\n",
    "    quality = analyze_code_quality(code, language)\n",
    "\n",
    "    prompt = f\"\"\"You are JULES, a code optimization expert. Analyze this {language} code and provide specific refactoring suggestions.\n",
    "\n",
    "Code quality score: {quality['quality_score']}/100\n",
    "Metrics: {json.dumps(quality['metrics'])}\n",
    "Vulnerabilities: {json.dumps(quality['vulnerabilities'])}\n",
    "\n",
    "Code:\n",
    "```{language}\n",
    "{code[:1500]}\n",
    "```\n",
    "\n",
    "Provide 3-5 specific, actionable refactoring suggestions:\"\"\"\n",
    "\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    formatted = code_analyzer.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    result = code_analyzer(formatted, max_new_tokens=400, temperature=0.3, do_sample=True)\n",
    "    suggestions = result[0]['generated_text'][len(formatted):].strip()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return {\n",
    "        'quality': quality,\n",
    "        'suggestions': suggestions,\n",
    "        'latency_ms': round(elapsed * 1000),\n",
    "        'device': device,\n",
    "    }\n",
    "\n",
    "def security_scan(code, language='javascript'):\n",
    "    \"\"\"Focused security vulnerability scan\"\"\"\n",
    "    start = time.time()\n",
    "    findings = []\n",
    "    lines = code.split('\\n')\n",
    "\n",
    "    for vuln_type, patterns in VULN_PATTERNS.items():\n",
    "        for pattern in patterns:\n",
    "            for i, line in enumerate(lines):\n",
    "                if re.search(pattern, line, re.IGNORECASE):\n",
    "                    findings.append({\n",
    "                        'type': vuln_type,\n",
    "                        'line': i + 1,\n",
    "                        'code': line.strip()[:100],\n",
    "                        'severity': 'critical' if vuln_type in ('sql_injection', 'hardcoded_secret') else 'high' if vuln_type in ('xss', 'eval_usage') else 'medium',\n",
    "                    })\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    return {\n",
    "        'findings': findings,\n",
    "        'total': len(findings),\n",
    "        'critical': len([f for f in findings if f['severity'] == 'critical']),\n",
    "        'high': len([f for f in findings if f['severity'] == 'high']),\n",
    "        'medium': len([f for f in findings if f['severity'] == 'medium']),\n",
    "        'passed': len(findings) == 0,\n",
    "        'latency_ms': round(elapsed * 1000),\n",
    "    }\n",
    "\n",
    "# Quick test\n",
    "test_code = '''function getUserData(req) {\\n  const query = `SELECT * FROM users WHERE id = ${req.params.id}`;\\n  const result = db.query(query);\\n  document.innerHTML = result.name;\\n  return result;\\n}'''\n",
    "print('=== JULES Quick Test ===')\n",
    "scan = security_scan(test_code)\n",
    "print(f'Security scan: {scan[\"total\"]} findings ({scan[\"critical\"]} critical, {scan[\"high\"]} high)')\n",
    "quality = analyze_code_quality(test_code)\n",
    "print(f'Quality score: {quality[\"quality_score\"]}/100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: FastAPI server\n",
    "from fastapi import FastAPI, Request\n",
    "import uvicorn\n",
    "import threading\n",
    "import asyncio\n",
    "import httpx\n",
    "\n",
    "app = FastAPI(title='JULES GPU Node', version='1.0.0')\n",
    "\n",
    "@app.get('/health')\n",
    "async def health():\n",
    "    return {\n",
    "        'status': 'active',\n",
    "        'node_id': HEADY_CONFIG['node_id'],\n",
    "        'node_role': HEADY_CONFIG['node_role'],\n",
    "        'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'cpu',\n",
    "        'gpu_memory_used_gb': round(torch.cuda.memory_allocated(0) / 1e9, 2) if torch.cuda.is_available() else 0,\n",
    "        'models': ['CodeBERT', 'TinyLlama-1.1B-Chat'],\n",
    "        'capabilities': HEADY_CONFIG['capabilities'],\n",
    "        'supported_tasks': list(SUPPORTED_TASKS.keys()),\n",
    "    }\n",
    "\n",
    "@app.post('/api/jules/quality')\n",
    "async def api_quality(request: Request):\n",
    "    data = await request.json()\n",
    "    return analyze_code_quality(data.get('code', ''), data.get('language', 'javascript'))\n",
    "\n",
    "@app.post('/api/jules/refactor')\n",
    "async def api_refactor(request: Request):\n",
    "    data = await request.json()\n",
    "    return suggest_refactoring(data.get('code', ''), data.get('language', 'javascript'))\n",
    "\n",
    "@app.post('/api/jules/security')\n",
    "async def api_security(request: Request):\n",
    "    data = await request.json()\n",
    "    return security_scan(data.get('code', ''), data.get('language', 'javascript'))\n",
    "\n",
    "@app.post('/api/jules/similarity')\n",
    "async def api_similarity(request: Request):\n",
    "    data = await request.json()\n",
    "    return find_similar_code(data.get('blocks', []))\n",
    "\n",
    "@app.post('/api/tasks/execute')\n",
    "async def execute_task(request: Request):\n",
    "    data = await request.json()\n",
    "    task_type = data.get('type', 'code_quality')\n",
    "    payload = data.get('payload', data)\n",
    "    try:\n",
    "        if task_type == 'code_quality':\n",
    "            result = analyze_code_quality(payload.get('code', ''), payload.get('language', 'javascript'))\n",
    "        elif task_type == 'optimization' or task_type == 'refactor':\n",
    "            result = suggest_refactoring(payload.get('code', ''), payload.get('language', 'javascript'))\n",
    "        elif task_type == 'security_scan':\n",
    "            result = security_scan(payload.get('code', ''), payload.get('language', 'javascript'))\n",
    "        elif task_type == 'similarity':\n",
    "            result = find_similar_code(payload.get('blocks', []))\n",
    "        else:\n",
    "            result = analyze_code_quality(payload.get('code', ''), payload.get('language', 'javascript'))\n",
    "        return {'success': True, 'node_id': HEADY_CONFIG['node_id'], 'task_type': task_type, 'result': result}\n",
    "    except Exception as e:\n",
    "        return {'success': False, 'error': str(e), 'node_id': HEADY_CONFIG['node_id']}\n",
    "\n",
    "print('JULES FastAPI ready: /health, /api/jules/quality, /api/jules/refactor, /api/jules/security, /api/jules/similarity, /api/tasks/execute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: ngrok tunnel + auto-register with HeadyCloud\n",
    "from pyngrok import ngrok, conf\n",
    "\n",
    "# Authenticate ngrok\n",
    "conf.get_default().auth_token = \"39ZBirdUD63xgta7yN7OFZpE84m_3QZyJTDno1b8Yhv9Nfy8s\"\n",
    "\n",
    "public_url = ngrok.connect(HEADY_CONFIG['port']).public_url\n",
    "print(f'JULES GPU Node live at: {public_url}')\n",
    "\n",
    "PUBLIC_URL = public_url\n",
    "\n",
    "async def register_with_clouds():\n",
    "    async with httpx.AsyncClient(timeout=15) as client:\n",
    "        for endpoint in HEADY_CONFIG['registration_endpoints']:\n",
    "            try:\n",
    "                resp = await client.post(endpoint, json={\n",
    "                    'node_id': HEADY_CONFIG['node_id'],\n",
    "                    'url': PUBLIC_URL,\n",
    "                    'role': HEADY_CONFIG['node_role'],\n",
    "                    'capabilities': HEADY_CONFIG['capabilities'],\n",
    "                    'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'cpu',\n",
    "                })\n",
    "                print(f'  Registered with {endpoint}: {resp.status_code}')\n",
    "            except Exception as e:\n",
    "                print(f'  Pending: {endpoint} ({e})')\n",
    "\n",
    "async def heartbeat_loop():\n",
    "    while True:\n",
    "        await asyncio.sleep(30)\n",
    "        async with httpx.AsyncClient(timeout=10) as client:\n",
    "            for layer, url in HEADY_CONFIG['cloud_layers'].items():\n",
    "                try:\n",
    "                    await client.post(f'{url}/api/nodes/heartbeat', json={\n",
    "                        'node_id': HEADY_CONFIG['node_id'],\n",
    "                        'status': 'active',\n",
    "                        'url': PUBLIC_URL,\n",
    "                        'metrics': {\n",
    "                            'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'cpu',\n",
    "                            'gpu_memory_used': round(torch.cuda.memory_allocated(0) / 1e9, 2) if torch.cuda.is_available() else 0,\n",
    "                            'models_loaded': 2,\n",
    "                        }\n",
    "                    })\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "asyncio.run(register_with_clouds())\n",
    "threading.Thread(target=lambda: asyncio.run(heartbeat_loop()), daemon=True).start()\n",
    "print(f'JULES GPU node live at {PUBLIC_URL} — accepting code analysis requests')\n",
    "# 0.0.0.0 is the Colab VM bind address for uvicorn, NOT a local service\n",
    "uvicorn.run(app, host='0.0.0.0', port=HEADY_CONFIG['port'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "JULES GPU Node — Code Optimization & Quality Engine",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
