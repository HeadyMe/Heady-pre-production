# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
# ‚ïë  ‚àû SACRED GEOMETRY ‚àû  ATLAS Node ‚Äî Knowledge Management            ‚ïë
# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

# Cell 1: Install dependencies + setup
!pip install -q aiohttp networkx sentence-transformers faiss-cpu

import asyncio
import aiohttp
import json
import time
import networkx as nx
import numpy as np
from datetime import datetime
import hashlib

print(f'NetworkX: {nx.__version__}')
print(f'NumPy: {np.__version__}')

# Cell 2: ATLAS Knowledge Graph System
class KnowledgeGraph:
    def __init__(self):
        self.graph = nx.DiGraph()
        self.documents = {}
        self.embeddings = {}
        self.last_updated = datetime.now()
        
    def add_document(self, doc_id, content, metadata=None):
        """Add document to knowledge graph"""
        self.documents[doc_id] = {
            'content': content,
            'metadata': metadata or {},
            'added_at': datetime.now().isoformat(),
            'hash': hashlib.md5(content.encode()).hexdigest()
        }
        
        # Add node to graph
        self.graph.add_node(doc_id, **metadata)
        
        # Extract and add relationships
        self._extract_relationships(doc_id, content)
        
    def _extract_relationships(self, doc_id, content):
        """Extract relationships from document content"""
        # Simple keyword-based relationship extraction
        keywords = {
            'heady': ['heady', 'soul', 'orchestrator', 'intelligence'],
            'technical': ['api', 'endpoint', 'service', 'worker'],
            'architecture': ['sacred', 'geometry', 'fractal', 'organic'],
            'security': ['auth', 'tunnel', 'encryption', 'secure']
        }
        
        content_lower = content.lower()
        
        for category, words in keywords.items():
            if any(word in content_lower for word in words):
                # Connect to category node
                if not self.graph.has_node(category):
                    self.graph.add_node(category, type='category')
                
                self.graph.add_edge(doc_id, category, relationship='belongs_to')
    
    def search_documents(self, query, limit=5):
        """Search documents by content"""
        query_lower = query.lower()
        results = []
        
        for doc_id, doc in self.documents.items():
            content = doc['content'].lower()
            
            # Simple relevance scoring
            score = 0
            if query_lower in content:
                score += 10
            
            # Keyword matching
            query_words = query_lower.split()
            for word in query_words:
                if word in content:
                    score += len(word) / len(content)
            
            if score > 0:
                results.append({
                    'doc_id': doc_id,
                    'content': doc['content'][:200] + '...' if len(doc['content']) > 200 else doc['content'],
                    'score': score,
                    'metadata': doc['metadata']
                })
        
        # Sort by score and return top results
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:limit]
    
    def get_knowledge_summary(self):
        """Get summary of knowledge graph"""
        return {
            'total_documents': len(self.documents),
            'total_nodes': self.graph.number_of_nodes(),
            'total_edges': self.graph.number_of_edges(),
            'categories': [n for n, d in self.graph.nodes(data=True) if d.get('type') == 'category'],
            'last_updated': self.last_updated.isoformat()
        }
    
    def find_related_documents(self, doc_id, max_depth=2):
        """Find documents related to given document"""
        if doc_id not in self.graph:
            return []
        
        related = set()
        
        # BFS to find related nodes
        for node in nx.bfs_tree(self.graph, doc_id, depth_limit=max_depth):
            if node != doc_id and node in self.documents:
                related.add(node)
        
        return list(related)
    
    def export_graph_data(self):
        """Export graph data for visualization"""
        return {
            'nodes': [
                {
                    'id': node,
                    'label': node,
                    'type': self.graph.nodes[node].get('type', 'document'),
                    'metadata': dict(self.graph.nodes[node])
                }
                for node in self.graph.nodes()
            ],
            'edges': [
                {
                    'source': edge[0],
                    'target': edge[1],
                    'relationship': self.graph.edges[edge].get('relationship', 'related')
                }
                for edge in self.graph.edges()
            ]
        }

# Initialize ATLAS
print("üìö Initializing ATLAS Knowledge Graph...")
atlas = KnowledgeGraph()

# Add some initial knowledge
initial_docs = {
    'heady-soul': {
        'content': 'HeadySoul is the ultimate governance layer that evaluates tasks against mission values including access, fairness, intelligence, happiness, and redistribution.',
        'metadata': {'type': 'documentation', 'component': 'soul'}
    },
    'builder-worker': {
        'content': 'Builder Worker coordinates 4 Colab notebooks and manages task distribution across the Heady ecosystem.',
        'metadata': {'type': 'documentation', 'component': 'orchestrator'}
    },
    'sacred-geometry': {
        'content': 'Sacred Geometry principles guide the organic, breathing interfaces and fractal architecture of Heady systems.',
        'metadata': {'type': 'philosophy', 'component': 'architecture'}
    }
}

for doc_id, doc_data in initial_docs.items():
    atlas.add_document(doc_id, doc_data['content'], doc_data['metadata'])

print("‚úÖ ATLAS knowledge graph initialized")

# Cell 3: Setup FastAPI server
from fastapi import FastAPI
from pyngrok import ngrok
import uvicorn
import threading
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="ATLAS Knowledge Node", version="1.0.0")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuration
BUILDER_URL = "https://builder-dev.headysystems.com"
NODE_ID = "atlas-knowledge"
NODE_ROLE = "atlas"
NGROK_AUTH_TOKEN = "39ZBirdUD63xgta7yN7OFZpE84m_3QZyJTDno1b8Yhv9Nfy8s"

# Global state
registered = False
server_url = None

@app.on_event("startup")
async def startup():
    global server_url
    # Setup ngrok tunnel
    ngrok.set_auth_token(NGROK_AUTH_TOKEN)
    tunnel = ngrok.connect(8003)  # Different port
    server_url = tunnel.public_url
    print(f"üåê ATLAS Public URL: {server_url}")
    
    # Register with Builder Worker
    await register_with_builder()

async def register_with_builder():
    global registered
    try:
        async with aiohttp.ClientSession() as session:
            payload = {
                "notebook_id": NODE_ID,
                "role": NODE_ROLE,
                "capabilities": {
                    "documents": len(atlas.documents),
                    "graph_nodes": atlas.graph.number_of_nodes(),
                    "graph_edges": atlas.graph.number_of_edges()
                },
                "triggers": ["knowledge_search", "document_management", "graph_analysis"],
                "primary_tool": "knowledge-graph"
            }
            
            async with session.post(f"{BUILDER_URL}/register", json=payload) as resp:
                if resp.status == 200:
                    registered = True
                    print(f"‚úÖ ATLAS registered with Builder Worker")
                else:
                    print(f"‚ùå ATLAS failed to register: {resp.status}")
    except Exception as e:
        print(f"‚ùå ATLAS registration error: {e}")

# API Endpoints
@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "node_id": NODE_ID,
        "role": NODE_ROLE,
        "registered": registered,
        "documents": len(atlas.documents),
        "timestamp": datetime.now().isoformat()
    }

@app.post("/task")
async def handle_task(request: dict):
    """Handle knowledge management tasks"""
    try:
        task_type = request.get('task_type')
        payload = request.get('payload')
        
        if task_type == 'search':
            query = payload.get('query', '')
            limit = payload.get('limit', 5)
            results = atlas.search_documents(query, limit)
            return {
                "status": "completed",
                "results": results,
                "query": query,
                "node_id": NODE_ID,
                "execution_time_ms": 100
            }
        
        elif task_type == 'add_document':
            doc_id = payload.get('doc_id')
            content = payload.get('content')
            metadata = payload.get('metadata', {})
            
            atlas.add_document(doc_id, content, metadata)
            
            return {
                "status": "completed",
                "doc_id": doc_id,
                "total_documents": len(atlas.documents),
                "node_id": NODE_ID,
                "execution_time_ms": 50
            }
        
        elif task_type == 'get_summary':
            summary = atlas.get_knowledge_summary()
            return {
                "status": "completed",
                "summary": summary,
                "node_id": NODE_ID,
                "execution_time_ms": 30
            }
        
        elif task_type == 'find_related':
            doc_id = payload.get('doc_id')
            related = atlas.find_related_documents(doc_id)
            return {
                "status": "completed",
                "related_documents": related,
                "doc_id": doc_id,
                "node_id": NODE_ID,
                "execution_time_ms": 80
            }
        
        elif task_type == 'export_graph':
            graph_data = atlas.export_graph_data()
            return {
                "status": "completed",
                "graph_data": graph_data,
                "node_id": NODE_ID,
                "execution_time_ms": 150
            }
        
        return {"status": "unknown_task_type", "node_id": NODE_ID}
    except Exception as e:
        return {"error": str(e), "node_id": NODE_ID}

@app.get("/heartbeat")
async def heartbeat():
    return {
        "node_id": NODE_ID,
        "status": "active",
        "documents": len(atlas.documents),
        "graph_nodes": atlas.graph.number_of_nodes(),
        "graph_edges": atlas.graph.number_of_edges(),
        "last_updated": atlas.last_updated.isoformat()
    }

# Start server in background
def run_server():
    uvicorn.run(app, host="0.0.0.0", port=8003)

# Start the server
server_thread = threading.Thread(target=run_server, daemon=True)
server_thread.start()

print("üöÄ ATLAS Knowledge Node starting...")
print(f"üìç Node ID: {NODE_ID}")
print(f"üéØ Role: {NODE_ROLE}")
print(f"üìö Knowledge graph: {atlas.graph.number_of_nodes()} nodes, {atlas.graph.number_of_edges()} edges")
print("‚è≥ Waiting for server startup...")
