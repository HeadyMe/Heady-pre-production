# Cloudflare Workers Protocols for Heady Systems

This document outlines protocols for integrating Cloudflare Workers into the Heady ecosystem to improve security, performance, and scalability.

## 1. Auth Gateway Worker

**Purpose:** Offload authentication and rate limiting to the edge to protect the origin server.

**Protocol:**

1.  **Intercept Requests:** The worker intercepts all incoming requests to the Heady API (`/api/*`).
2.  **Validate API Key:**
    *   Check for `x-heady-api-key` header.
    *   Compare it against a secret stored in Cloudflare Workers Secrets (`HEADY_API_KEY`).
    *   Use timing-safe comparison to prevent timing attacks.
3.  **Rate Limiting:**
    *   Use Cloudflare Rate Limiting (or a Durable Object/KV based counter) to track requests per IP.
    *   Reject requests exceeding the limit (e.g., 120 req/min) with `429 Too Many Requests`.
4.  **Forward or Reject:**
    *   If valid, forward the request to the origin (Heady Server).
    *   If invalid, return `401 Unauthorized`.

**Example Code Snippet:**

```javascript
export default {
  async fetch(request, env) {
    const apiKey = request.headers.get("x-heady-api-key");
    if (apiKey !== env.HEADY_API_KEY) {
      return new Response("Unauthorized", { status: 401 });
    }
    // ... rate limiting logic ...
    return fetch(request);
  }
}
```

## 2. Inference Caching Worker

**Purpose:** Cache Hugging Face inference results to reduce costs and latency.

**Protocol:**

1.  **Intercept Inference Requests:** Listen for POST requests to `/api/hf/*`.
2.  **Generate Cache Key:**
    *   Create a hash (SHA-256) of the request body (model + inputs + parameters).
3.  **Check Cache (KV):**
    *   Look up the key in Cloudflare KV.
    *   If found, return the cached JSON response immediately.
4.  **Fetch & Cache:**
    *   If not found, forward the request to the origin (or directly to Hugging Face API if credentials allow).
    *   Store the response in KV with a TTL (e.g., 24 hours).
    *   Return the response to the user.

**Benefits:**
*   Reduces API calls to Hugging Face.
*   Speeds up repeated queries (common in testing/development).

## 3. Static Asset Delivery Worker

**Purpose:** Serve the Admin IDE and frontend assets from the edge.

**Protocol:**

1.  **Storage:** Upload the contents of the `public/` directory to Cloudflare R2 or KV (Workers Sites).
2.  **Routing:**
    *   Map the worker to the root domain (or `/admin` path).
    *   Serve `index.html` for the root path.
    *   Serve static files (JS, CSS) based on the path.
3.  **Caching:**
    *   Set aggressive `Cache-Control` headers for hashed assets.
    *   Use `ETag` for efficient revalidation.

**Integration:**
*   The Heady server can verify the worker's presence via a health check header.
*   Updates to the frontend are deployed via `wrangler deploy`.

## Implementation Steps

1.  Install Wrangler: `npm install -g wrangler`
2.  Initialize Worker: `wrangler init heady-gateway`
3.  Configure `wrangler.toml` with environment variables.
4.  Deploy: `wrangler deploy`

---
*Generated by Heady Systems Protocol Droid*
